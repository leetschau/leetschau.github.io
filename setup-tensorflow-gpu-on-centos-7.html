<!DOCTYPE html>
<html lang="en-US">
    <head>
        <meta charset="utf-8"> 
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Li Chao" />
        <meta name="copyright" content="Li Chao" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="tensorflow, centos, gpu, python, Tech, " />

<meta property="og:title" content="Setup Tensorflow GPU on CentOS 7"/>
<meta property="og:url" content="http://leetschau.github.io/setup-tensorflow-gpu-on-centos-7.html" />
<meta property="og:description" content="首先创建用户，安装必要的软件： useradd -m -s /bin/bash -G wheel leo passwd leo su - leo sudo yum install git wget 本段代码不执行： 原本计划安装 asdf + Python 作为 Tensorflow 运行环境， 但 asdf 在 CentOS 7 上编译 Python 缺少 OpenSSL 包， 安装相关包后仍然报错，放弃： sudo yum install git zlib-devel sqlite-devel openssl openssl-libs openssl-devel libffi \ readline-devel ncurses-devel …" />
<meta property="og:site_name" content="DarkMatter in Cyberspace" />
<meta property="og:article:author" content="Li Chao" />
<meta property="og:article:published_time" content="2020-05-19T15:44:27+08:00" />
<meta property="" content="2020-06-03T09:43:40+08:00" />
<meta name="twitter:title" content="Setup Tensorflow GPU on CentOS 7">
<meta name="twitter:description" content="首先创建用户，安装必要的软件： useradd -m -s /bin/bash -G wheel leo passwd leo su - leo sudo yum install git wget 本段代码不执行： 原本计划安装 asdf + Python 作为 Tensorflow 运行环境， 但 asdf 在 CentOS 7 上编译 Python 缺少 OpenSSL 包， 安装相关包后仍然报错，放弃： sudo yum install git zlib-devel sqlite-devel openssl openssl-libs openssl-devel libffi \ readline-devel ncurses-devel …">

        <title>Setup Tensorflow GPU on CentOS 7 · DarkMatter in Cyberspace
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.1/css/font-awesome.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="http://leetschau.github.io/theme/css/pygments.css" media="screen">
        <link rel="stylesheet" type="text/css" href="http://leetschau.github.io/theme/tipuesearch/tipuesearch.css" media="screen">
        <link rel="stylesheet" type="text/css" href="http://leetschau.github.io/theme/css/elegant.css" media="screen">
        <link rel="stylesheet" type="text/css" href="http://leetschau.github.io/theme/css/custom.css" media="screen">
    </head>
    <body>
        <div id="content-sans-footer">
        <div class="navbar navbar-static-top">
            <div class="navbar-inner">
                <div class="container-fluid">
                    <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </a>
                    <a class="brand" href="http://leetschau.github.io/"><span class=site-name>DarkMatter in Cyberspace</span></a>
                    <div class="nav-collapse collapse">
                        <ul class="nav pull-right top-menu">
                            <li ><a href="http://leetschau.github.io">Home</a></li>
                            <li ><a href="http://leetschau.github.io/categories.html">Categories</a></li>
                            <li ><a href="http://leetschau.github.io/tags.html">Tags</a></li>
                            <li ><a href="http://leetschau.github.io/archives.html">Archives</a></li>
                            <li><form class="navbar-search" action="http://leetschau.github.io/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div class="container-fluid">
            <div class="row-fluid">
                <div class="span1"></div>
                <div class="span10">
<article>
<div class="row-fluid">
    <header class="page-header span10 offset2">
    <h1><a href="http://leetschau.github.io/setup-tensorflow-gpu-on-centos-7.html"> Setup Tensorflow GPU on CentOS 7 </a></h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">

            
            <hr>
<p>首先创建用户，安装必要的软件：</p>
<div class="highlight"><pre><span></span><code><span class="err">useradd -m -s /bin/bash -G wheel leo</span>
<span class="err">passwd leo</span>
<span class="err">su - leo</span>
<span class="err">sudo yum install git wget</span>
</code></pre></div>


<p>本段代码不执行：
原本计划安装 asdf + Python 作为 Tensorflow 运行环境，
但 asdf 在 CentOS 7 上编译 Python 缺少 OpenSSL 包，
安装相关包后仍然报错，放弃：</p>
<div class="highlight"><pre><span></span><code><span class="err">sudo yum install git zlib-devel sqlite-devel openssl openssl-libs </span>
<span class="err">  openssl-devel libffi \</span>
<span class="err">  readline-devel ncurses-devel</span>
<span class="err">git clone https://github.com/asdf-vm/asdf.git ~/.asdf --branch v0.7.8</span>
<span class="err">echo -e &#39;\n. $HOME/.asdf/asdf.sh&#39; &gt;&gt; ~/.bashrc</span>
<span class="err">asdf plugin-add python</span>
<span class="err">asdf install python 3.7.7</span>
</code></pre></div>


<p>改用 conda 安装 tensorflow 成功，下面是详细过程。</p>
<h1>Install GPU Driver</h1>
<div class="highlight"><pre><span></span><code><span class="err">wget http://us.download.nvidia.com/XFree86/Linux-x86_64/415.27/NVIDIA-Linux-x86_64-415.27.run</span>
<span class="err">chmod 755 NVIDIA-Linux-x86_64-415.27.run</span>
<span class="err">sudo ./NVIDIA-Linux-x86_64-415.27.run</span>
</code></pre></div>


<p>安装程序提示更高版本驱动已安装，此过程终止，
检查驱动安装效果（smi means system management interface）：</p>
<div class="highlight"><pre><span></span><code>$ nvidia-smi
Wed Jun  <span class="m">3</span> <span class="m">07</span>:18:08 <span class="m">2020</span>       
+-----------------------------------------------------------------------------+
<span class="p">|</span> NVIDIA-SMI <span class="m">440</span>.33.01    Driver Version: <span class="m">440</span>.33.01    CUDA Version: <span class="m">10</span>.2     <span class="p">|</span>
<span class="p">|</span>-------------------------------+----------------------+----------------------+
<span class="p">|</span> GPU  Name        Persistence-M<span class="p">|</span> Bus-Id        Disp.A <span class="p">|</span> Volatile Uncorr. ECC <span class="p">|</span>
<span class="p">|</span> Fan  Temp  Perf  Pwr:Usage/Cap<span class="p">|</span>         Memory-Usage <span class="p">|</span> GPU-Util  Compute M. <span class="p">|</span>
<span class="p">|</span><span class="o">===============================</span>+<span class="o">======================</span>+<span class="o">======================</span><span class="p">|</span>
<span class="p">|</span>   <span class="m">0</span>  GeForce RTX <span class="m">207</span>...  Off  <span class="p">|</span> <span class="m">00000000</span>:01:00.0 Off <span class="p">|</span>                  N/A <span class="p">|</span>
<span class="p">|</span> <span class="m">28</span>%   43C    P0    25W / 215W <span class="p">|</span>      0MiB /  7979MiB <span class="p">|</span>      <span class="m">0</span>%      Default <span class="p">|</span>
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
<span class="p">|</span> Processes:                                                       GPU Memory <span class="p">|</span>
<span class="p">|</span>  GPU       PID   Type   Process name                             Usage      <span class="p">|</span>
<span class="p">|</span><span class="o">=============================================================================</span><span class="p">|</span>
<span class="p">|</span>  No running processes found                                                 <span class="p">|</span>
+-----------------------------------------------------------------------------+
</code></pre></div>


<p>输出包含两张表格，第一张主要是汇总信息，第二张主要是实时使用情况，
下面分别说明。</p>
<h2>检查 GPU 内存容量</h2>
<div class="highlight"><pre><span></span><code>$ pip install gpustat   <span class="c1"># or: conda install -c conda-forge gpustat</span>
$ gpustat
centos7                    Wed Jun  <span class="m">3</span> <span class="m">08</span>:34:47 <span class="m">2020</span>  <span class="m">440</span>.33.01
<span class="o">[</span><span class="m">0</span><span class="o">]</span> GeForce RTX <span class="m">2070</span> SUPER <span class="p">|</span> <span class="m">50</span><span class="err">&#39;</span>C,   <span class="m">0</span> % <span class="p">|</span>     <span class="m">0</span> /  <span class="m">7979</span> MB <span class="p">|</span>
</code></pre></div>


<p>与上面 <code>nvidia-smi</code> 报告的 <em>Memory-Usage</em> 部分一致，都是 7979MB。</p>
<p>专门查询内存部分：</p>
<div class="highlight"><pre><span></span><code>$ nvidia-smi -q -d <span class="nv">memory</span>

<span class="o">==============</span>NVSMI <span class="nv">LOG</span><span class="o">==============</span>

Timestamp                           : Wed Jun  <span class="m">3</span> <span class="m">07</span>:50:00 <span class="m">2020</span>
Driver Version                      : <span class="m">440</span>.33.01
CUDA Version                        : <span class="m">10</span>.2

Attached GPUs                       : <span class="m">1</span>
GPU <span class="m">00000000</span>:01:00.0
    FB Memory Usage
        Total                       : <span class="m">7979</span> MiB
        Used                        : <span class="m">0</span> MiB
        Free                        : <span class="m">7979</span> MiB
    BAR1 Memory Usage
        Total                       : <span class="m">256</span> MiB
        Used                        : <span class="m">2</span> MiB
        Free                        : <span class="m">254</span> MiB


$ lspci <span class="p">|</span> grep NVIDIA    <span class="c1"># get the device ID is `01:00.0`</span>
<span class="m">01</span>:00.0 VGA compatible controller: NVIDIA Corporation Device 1e84 <span class="o">(</span>rev a1<span class="o">)</span>
...

$ lspci -v -s <span class="m">01</span>:00.0 <span class="p">|</span> grep Memory
        Memory at de000000 <span class="o">(</span><span class="m">32</span>-bit, non-prefetchable<span class="o">)</span> <span class="o">[</span><span class="nv">size</span><span class="o">=</span>16M<span class="o">]</span>
        Memory at c0000000 <span class="o">(</span><span class="m">64</span>-bit, prefetchable<span class="o">)</span> <span class="o">[</span><span class="nv">size</span><span class="o">=</span>256M<span class="o">]</span>
        Memory at d0000000 <span class="o">(</span><span class="m">64</span>-bit, prefetchable<span class="o">)</span> <span class="o">[</span><span class="nv">size</span><span class="o">=</span>32M<span class="o">]</span>
</code></pre></div>


<p>一个命令的 FB memory 显示设备内容容量，也是 7979 MB，即 8GB，
BAR1 memory 为 256MB，是CPU或者其他应用可以使用的内存，与 <code>lspci</code> 给出的结果一致。
具体含义参考 <code>man nvidia-smi</code> 中相关章节的说明。</p>
<h2>监控 GPU 内存实时使用情况</h2>
<p>每两秒刷新一下监控状态：</p>
<div class="highlight"><pre><span></span><code><span class="err">nvidia-smi -l 2        # by -l option</span>
<span class="err">gpustat -cp -i 2       # by -i option</span>
<span class="err">watch -n 2 nvidia-smi  # by -n option of watch</span>
</code></pre></div>


<p>Note: 如果 <code>watch</code> 后面的命令有颜色，
可以为 <code>watch</code> 命令添加 <code>-c</code> 选项使其正确解析颜色编码。</p>
<p>可以指定输出内容和格式（仍然是输出到屏幕）：</p>
<div class="highlight"><pre><span></span><code><span class="err">nvidia-smi --query-compute-apps=pid,process_name,used_memory --format=csv</span>
</code></pre></div>


<p>查看哪些进程使用显卡：<code>lsof /dev/nvidia*</code>.</p>
<h1>Install CUDA 10.2 and CUPTI</h1>
<p>根据 <a href="https://docs.nvidia.com/deploy/cuda-compatibility/index.html">CUDA Compatibility</a>,
Cuda 10.2 支持 49 服务器的 驱动版本：440.33.</p>
<div class="highlight"><pre><span></span><code><span class="n">wget</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">developer</span><span class="p">.</span><span class="n">download</span><span class="p">.</span><span class="n">nvidia</span><span class="p">.</span><span class="n">com</span><span class="o">/</span><span class="n">compute</span><span class="o">/</span><span class="n">cuda</span><span class="o">/</span><span class="mi">10</span><span class="p">.</span><span class="mi">2</span><span class="o">/</span><span class="n">Prod</span><span class="o">/</span><span class="n">local_installers</span><span class="o">/</span><span class="n">cuda_10</span><span class="p">.</span><span class="mi">2</span><span class="p">.</span><span class="mi">89</span><span class="n">_440</span><span class="p">.</span><span class="mi">33</span><span class="p">.</span><span class="mi">01</span><span class="n">_linux</span><span class="p">.</span><span class="n">run</span>
<span class="n">sudo</span> <span class="n">sh</span> <span class="n">cuda_10</span><span class="p">.</span><span class="mi">2</span><span class="p">.</span><span class="mi">89</span><span class="n">_440</span><span class="p">.</span><span class="mi">33</span><span class="p">.</span><span class="mi">01</span><span class="n">_linux</span><span class="p">.</span><span class="n">run</span>
<span class="o">#</span> <span class="n">make</span> <span class="n">sure</span> <span class="n">CUPTI</span> <span class="k">in</span> <span class="n">the</span> <span class="n">installation</span> <span class="n">list</span> <span class="p">(</span><span class="k">in</span> <span class="n">cuda</span> <span class="n">command</span> <span class="n">line</span> <span class="n">tools</span> <span class="n">menu</span><span class="p">)</span>


<span class="o">#</span><span class="p">:</span> <span class="k">add</span> <span class="s1">&#39;/usr/local/cuda-10.2/bin&#39;</span> <span class="k">into</span> <span class="n">PATH</span>
<span class="n">sudo</span> <span class="n">echo</span> <span class="s1">&#39;export PATH=$PATH:/usr/local/cuda-10.2/bin&#39;</span> <span class="o">&gt;</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">profile</span><span class="p">.</span><span class="n">d</span><span class="o">/</span><span class="n">cuda</span><span class="p">.</span><span class="n">sh</span>
<span class="n">sudo</span> <span class="n">echo</span> <span class="s1">&#39;export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64&#39;</span> <span class="o">&gt;&gt;</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">profile</span><span class="p">.</span><span class="n">d</span><span class="o">/</span><span class="n">cuda</span><span class="p">.</span><span class="n">sh</span>
<span class="k">source</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">profile</span><span class="p">.</span><span class="n">d</span><span class="o">/</span><span class="n">cuda</span><span class="p">.</span><span class="n">sh</span>

<span class="o">#</span><span class="p">:</span> <span class="k">add</span> <span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="k">local</span><span class="o">/</span><span class="n">cuda</span><span class="o">-</span><span class="mi">10</span><span class="p">.</span><span class="mi">2</span><span class="o">/</span><span class="n">lib64</span> <span class="k">to</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">ld</span><span class="p">.</span><span class="n">so</span><span class="p">.</span><span class="n">conf</span> <span class="k">and</span> <span class="n">run</span> <span class="n">ldconfig</span> <span class="k">as</span> <span class="n">root</span>
<span class="n">sudo</span> <span class="n">echo</span> <span class="err">&#39;</span><span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="k">local</span><span class="o">/</span><span class="n">cuda</span><span class="o">-</span><span class="mi">10</span><span class="p">.</span><span class="mi">2</span><span class="o">/</span><span class="n">lib64</span><span class="o">`</span> <span class="o">&gt;&gt;</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">ld</span><span class="p">.</span><span class="n">so</span><span class="p">.</span><span class="n">conf</span><span class="p">.</span><span class="n">d</span><span class="o">/</span><span class="n">cuda</span><span class="o">-</span><span class="mi">10</span><span class="o">-</span><span class="mi">2</span><span class="p">.</span><span class="n">conf</span>
<span class="n">sudo</span> <span class="n">ldocnfig</span>
</code></pre></div>


<p>Verify Installation:</p>
<p>只要下面的文件在基本可以说明安装了：</p>
<div class="highlight"><pre><span></span><code>$ whereis cuda
cuda: /usr/local/cuda
$ ls -l <span class="k">$(</span>whereis cuda<span class="k">)</span>
</code></pre></div>


<h1>Install cuDNN SDK</h1>
<p>Register as NVidia developer and download the following files:</p>
<ul>
<li>cuDNN Runtime Library for RedHat/Centos 7.3 (RPM)</li>
<li>cuDNN Developer Library for RedHat/Centos 7.3 (RPM)</li>
<li>cuDNN Code Samples and User Guide for RedHat/Centos 7.3 (RPM)</li>
</ul>
<p>Install these files:</p>
<div class="highlight"><pre><span></span><code><span class="err">sudo rpm -ivh libcudnn7-7.6.5.33-1.cuda10.2.x86_64.rpm</span>
<span class="err">sudo rpm -ivh libcudnn7-devel-7.6.5.33-1.cuda10.2.x86_64.rpm</span>
<span class="err">sudo rpm -ivh libcudnn7-doc-7.6.5.33-1.cuda10.2.x86_64.rpm</span>
</code></pre></div>


<p>Verify Installation:</p>
<div class="highlight"><pre><span></span><code>$ cat <span class="k">$(</span>whereis cudnn <span class="p">|</span> awk -F<span class="s1">&#39;: &#39;</span> <span class="s1">&#39;{print $2}&#39;</span><span class="k">)</span> <span class="p">|</span> grep CUDNN_MAJOR -A <span class="m">2</span>
<span class="c1">#define CUDNN_MAJOR 7</span>
<span class="c1">#define CUDNN_MINOR 6</span>
<span class="c1">#define CUDNN_PATCHLEVEL 5</span>
--
<span class="c1">#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)</span>

<span class="c1">#include &quot;driver_types.h&quot;</span>
</code></pre></div>


<h1>Install MiniConda, TensorFlow and run demo</h1>
<div class="highlight"><pre><span></span><code><span class="n">conda</span> <span class="n">create</span> <span class="o">-</span><span class="n">n</span> <span class="n">tfgpu</span>
<span class="n">conda</span> <span class="n">activate</span> <span class="n">tfgpu</span>
<span class="n">conda</span> <span class="n">install</span> <span class="n">tensorflow</span><span class="o">-</span><span class="n">gpu</span> <span class="n">ipython</span>

<span class="n">ipython</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>

<span class="c1">#: GPU verification</span>

<span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">is_built_with_cuda</span><span class="p">()</span>  <span class="c1"># True</span>

<span class="c1">#: at least one GPU working</span>
<span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">is_gpu_available</span><span class="p">()</span>    <span class="c1"># True</span>

<span class="c1">#: the first GPU name, where operations will run</span>
<span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">()</span>  <span class="c1"># &#39;/device:GPU:0&#39;</span>

<span class="c1">#: print the list of all available GPU devices</span>
<span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">)</span>
<span class="c1"># [PhysicalDevice(name=&#39;/physical_device:GPU:0&#39;, device_type=&#39;GPU&#39;)]</span>

<span class="kn">from</span> <span class="nn">tensorflow.python.client</span> <span class="kn">import</span> <span class="n">device_lib</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">device_lib</span><span class="o">.</span><span class="n">list_local_devices</span><span class="p">()</span>
<span class="nb">len</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>

<span class="n">mnist</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mf">255.0</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div>
            
            
            <hr/>
            <script src="https://utteranc.es/client.js"
                    repo="leetschau/leetschau.github.io"
                    issue-term="pathname"
                    theme="github-light"
                    crossorigin="anonymous"
                    async>
            </script>
            <hr/>
        </div>
        <section>
        <div class="span2" style="float:right;font-size:0.9em;">
            <h4>Published</h4>
            <time pubdate="pubdate" datetime="2020-05-19T15:44:27+08:00">May 19, 2020</time>

<h4>Last Updated</h4>
<time datetime="2020-06-03T09:43:40+08:00">Jun 3, 2020</time>

            <h4>Category</h4>
            <a class="category-link" href="http://leetschau.github.io/categories.html#tech-ref">Tech</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="http://leetschau.github.io/tags.html#centos-ref">centos
                    <span>25</span>
</a></li>
                <li><a href="http://leetschau.github.io/tags.html#gpu-ref">gpu
                    <span>1</span>
</a></li>
                <li><a href="http://leetschau.github.io/tags.html#python-ref">python
                    <span>136</span>
</a></li>
                <li><a href="http://leetschau.github.io/tags.html#tensorflow-ref">tensorflow
                    <span>3</span>
</a></li>
            </ul>
<h4>Contact</h4>
    <a href="#" title="My You can add links in your config file Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-you can add links in your config file sidebar-social-links"></i></a>
    <a href="#" title="My Another social link Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-another social link sidebar-social-links"></i></a>
        </div>
        </section>
</div>
</article>
                </div>
                <div class="span1"></div>
            </div>
        </div>
        <div id="push"></div>
    </div>
<footer>
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page">Pelican</a>. Theme: <a href="http://oncrashreboot.com/pelican-elegant" title="Theme Elegant Home Page">Elegant</a> by <a href="http://oncrashreboot.com" title="Talha Mansoor Home Page">Talha Mansoor</a></li>
    </ul>
</div>
</footer>            <script src="http://code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    
    </body>
    <!-- Theme: Elegant built for Pelican
    License : http://oncrashreboot.com/pelican-elegant -->
</html>