<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: File | Dark Matter in Cyberspace]]></title>
  <link href="http://leetschau.github.io/blog/categories/file/atom.xml" rel="self"/>
  <link href="http://leetschau.github.io/"/>
  <updated>2016-02-21T11:06:40+08:00</updated>
  <id>http://leetschau.github.io/</id>
  <author>
    <name><![CDATA[Li Chao]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Compare Users in 2 Days With Spark]]></title>
    <link href="http://leetschau.github.io/blog/2015/01/04/173843/"/>
    <updated>2015-01-04T17:38:43+08:00</updated>
    <id>http://leetschau.github.io/blog/2015/01/04/173843</id>
    <content type="html"><![CDATA[<p>We have 2 log files. One contains logs created in 2014.11.22, the other all in 2014.11.23.
Each have about 240 million logs in it, with file size 30GB.</p>

<p>The log in these files are like this:</p>

<blockquote><p>&ldquo;460015482006002&rdquo;,&ldquo;深圳市&rdquo;,&ldquo;广东省&rdquo;,&ldquo;2014-12-22  16:46:04&rdquo;,&ldquo;2014-12-22  16:46:04&rdquo;,&ldquo;42705&rdquo;,&ldquo;16111&rdquo;,&ldquo;460014270516111&rdquo;,&ldquo;MAP&rdquo;</p></blockquote>

<p>The number in the first column &ldquo;460015482006002&rdquo; represents a unique user, which is called &ldquo;IMSI&rdquo;.
We need to find all IMSI number <strong>only</strong> exists in 2014.11.22.</p>

<p>Given the huge size of log files, we compute with Apache Spark.</p>

<p>Create only22.scala:</p>

<pre><code>import java.util.Date
import java.util.Calendar
import java.util.concurrent.TimeUnit

val SIG_DATA1 = "datamine/drawdata_20141122_cs.utf8.csv"
val SIG_DATA2 = "datamine/drawdata_20141123_cs.utf8.csv"
val USER_ID_POS = 1

def get_users(data: String): Set[String] = {
  val raw_data = sc.textFile(data).map(_.split("\"").toList)
  val raw_sig_map = raw_data.filter(x =&gt; x.size &gt; 17)
  val users = raw_sig_map.map(_(USER_ID_POS)).distinct
  return users.toArray.toSet
}

val u1 = get_users(SIG_DATA1)
val u2 = get_users(SIG_DATA2)
val only22 = u1 -- u2
scala.tools.nsc.io.File("only22.txt").writeAll(only22.toString)
</code></pre>

<p>Run it: <code>spark-shell --master spark://cloud142:7077 --driver-memory 6g --driver-cores 5 --total-executor-cores 28 --executor-memory 20g -i only22.scala</code></p>

<p>In file only22.txt, all elements in the set are written in one line.
So we have to replace all &ldquo;,&rdquo; with newline character: <code>sed -i 's/,/\n/g' only22.txt</code>;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Debug Binary File Reading C++ Codes With Gdb]]></title>
    <link href="http://leetschau.github.io/blog/2014/05/23/171938/"/>
    <updated>2014-05-23T17:19:38+08:00</updated>
    <id>http://leetschau.github.io/blog/2014/05/23/171938</id>
    <content type="html"><![CDATA[<p>We need debug a C++ file, which read and analyze a binary file. We use gdb and xxd in this case. In tmux, split a window horizontally, run gdb in the upper bigger pane, and list file content in lower smaller pane.</p>

<pre><code>$ tmux new -s basic
A-f,-   // split window, I define &lt;prefix&gt; of tmux as A-f in ~/.tmux.conf: set -g prefix M-f
A-f,JJ  // make upper pane larger
$ xxd -l 33 &lt;input-binary-file&gt;.dat   // print first 32 bytes of this file
0000000: 202a 463b 862e d108 2100 ab55 8006 f407   *F;....!..U....
0000010: 0000 0000 0a0e 0401 0102 1800 5201 0501  ............R...
0000020: 15
A-f,k   // jump to upper window
$ cat readfile.cc
#include &lt;fstream&gt;
#include &lt;iterator&gt;
#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;string&gt;
using namespace std;

typedef unsigned char BYTE;

BYTE *read_section(FILE *istream, int *length);

int main() {
    string filename = "/home/chad/docs/eclipsews/MrParser/doc/ns-output/1296_2014_04_25_10_00_MR.dat";
    char *fn = const_cast&lt;char*&gt;(filename.c_str());
    FILE *rstream = fopen(fn, "rb"); // 打开.dat文件
    BYTE *buffer = NULL;
    int length = 0;
    buffer = read_section(rstream, &amp;length);
    fclose(rstream);
    printf("Read file length: %d\n", length);
    return 0;
}

BYTE *read_section(FILE *istream, int *length) {
    int count = 0;
    size_t ret = 0;
    BYTE buf[128];
    BYTE *buffer = NULL;

    ret = fread(buf, sizeof(char), 8, istream); if (8 != ret) return NULL;
    ret = fread(buf, sizeof(char), 2, istream); if (2 != ret) return NULL;
    *length = buf[1] * 256 + buf[0];
    if ( 0 == *length) return NULL;
    buffer = new BYTE[*length];
    fseek(istream, -10, SEEK_CUR);
    ret = fread(buffer, sizeof(char), *length, istream);
    if (*length != ret) {
        delete [] buffer;
        return NULL;
    }
    return buffer;
}
$ g++ -g readfile.cc -o rr
$ gdb rr
l
// list source code, we want to probe the content of variable "buffer" after the "fread" operation. So we add a breakpoint after that line
b 37
r
(gdb) p/x *buffer@33
$1 = {0x20, 0x2a, 0x46, 0x3b, 0x86, 0x2e, 0xd1, 0x8, 0x21, 0x0, 0xab, 0x55, 0x80, 0x6, 0xf4, 0x7, 0x0, 0x0, 0x0, 0x0, 0xa, 0xe, 0x4, 0x1, 0x1,
  0x2, 0x18, 0x0, 0x52, 0x1, 0x5, 0x1, 0x15}
p/x buffer[0]
$2 = 0x20
c
q
</code></pre>

<p>where l=list, r=run, p/x means &ldquo;print value in hex format&rdquo;, c=continue, q=quit.
You can see the bytes of &ldquo;buffer&rdquo; is exactly the same with the output of xxd command: 0x20, 0x2a, &hellip;, 0x15.</p>

<p>The format of gdb&rsquo;s print see <a href="http://www.delorie.com/gnu/docs/gdb/gdb_55.html">8.4 Output formats</a> for details.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Analyze Binary File in Linux]]></title>
    <link href="http://leetschau.github.io/blog/2014/04/29/093749/"/>
    <updated>2014-04-29T09:37:49+08:00</updated>
    <id>http://leetschau.github.io/blog/2014/04/29/093749</id>
    <content type="html"><![CDATA[<p>On Linux there are some utility to analyze binary files, such as xxd, od, hexdump, which are much convenient and powerful than UltraEdit on Windows.</p>

<pre><code>$ cat test
abcdefg
hijklmn
opq
rst
uvw
xyz

$ xxd test
0000000: 6162 6364 6566 670a 6869 6a6b 6c6d 6e0a  abcdefg.hijklmn.
0000010: 6f70 710a 7273 740a 7576 770a 7879 7a0a  opq.rst.uvw.xyz.

$ xxd -b test
0000000: 01100001 01100010 01100011 01100100 01100101 01100110  abcdef
0000006: 01100111 00001010 01101000 01101001 01101010 01101011  g.hijk
000000c: 01101100 01101101 01101110 00001010 01101111 01110000  lmn.op
0000012: 01110001 00001010 01110010 01110011 01110100 00001010  q.rst.
0000018: 01110101 01110110 01110111 00001010 01111000 01111001  uvw.xy
000001e: 01111010 00001010                                      z.

$ xxd -b -s 10 test
000000a: 01101010 01101011 01101100 01101101 01101110 00001010  jklmn.
0000010: 01101111 01110000 01110001 00001010 01110010 01110011  opq.rs
0000016: 01110100 00001010 01110101 01110110 01110111 00001010  t.uvw.
000001c: 01111000 01111001 01111010 00001010                    xyz.

$ xxd -b -s 0x10 test
0000010: 01101111 01110000 01110001 00001010 01110010 01110011  opq.rs
0000016: 01110100 00001010 01110101 01110110 01110111 00001010  t.uvw.
000001c: 01111000 01111001 01111010 00001010                    xyz.

$ xxd -b -s 3 -l 10 test
0000003: 01100100 01100101 01100110 01100111 00001010 01101000  defg.h
0000009: 01101001 01101010 01101011 01101100                    ijkl

$ xxd -b -s 3 -l 10 -c 1 test
0000003: 01100100  d
0000004: 01100101  e
0000005: 01100110  f
0000006: 01100111  g
0000007: 00001010  .
0000008: 01101000  h
0000009: 01101001  i
000000a: 01101010  j
000000b: 01101011  k
000000c: 01101100  l

$ xxd -p -s 3 -l 10 test
646566670a68696a6b6c
</code></pre>

<p>Compare hex and binary files line by line:</p>

<pre><code>$ xxd -b -c 2 binaryfile &gt; o1
$ xxd -c 2 binaryfile &gt; o2
$ paste o1 o2
0000000: 11001101 11001101  ..  0000000: cdcd  ..
0000002: 00000000 00101110  ..  0000002: 002e  ..
0000004: 10011000 00000011  ..  0000004: 9803  ..
0000006: 11101011 00100000  .   0000006: eb20  . 
0000008: 00000010 10001011  ..  0000008: 028b  ..
000000a: 01000011 00111000  C8  000000a: 4338  C8
000000c: 00001011 10111111  ..  000000c: 0bbf  ..
000000e: 10011011 01100101  .e  000000e: 9b65  .e
0000010: 10000111 00001111  ..  0000010: 870f  ..
0000012: 00100000 00100000      0000012: 2020    
0000014: 00000010 00011100  ..  0000014: 021c  ..
0000016: 01111001 00000001  y.  0000016: 7901  y.
0000018: 01110110 01011100  v\  0000018: 765c  v\
000001a: 00000000 00011011  ..  000001a: 001b  ..
000001c: 00101100 01111101  ,}  000001c: 2c7d  ,}
000001e: 00010001 00011011  ..  000001e: 111b  ..
0000020: 01100101 10001111  e.  0000020: 658f  e.
0000022: 10100010 01010100  .T  0000022: a254  .T
0000024: 10101000 01011011  .[  0000024: a85b  .[
0000026: 00101100 10010011  ,.  0000026: 2c93  ,.
0000028: 11100101 01110100  .t  0000028: e574  .t
000002a: 00100010 11011001  ".  000002a: 22d9  ".
000002c: 01100000 01100000  ``  000002c: 6060  ``
000002e: 11101001 00011111  ..  000002e: e91f  ..
0000030: 00000000 00000000  ..  0000030: 0000  ..
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Unicode and File I/O in Python 2.X and 3.X]]></title>
    <link href="http://leetschau.github.io/blog/2014/02/17/082031/"/>
    <updated>2014-02-17T08:20:31+08:00</updated>
    <id>http://leetschau.github.io/blog/2014/02/17/082031</id>
    <content type="html"><![CDATA[<p>In Python 2.x, the default string is byte string, which means every byte is convert to a character.
If you write a Unicode string, you have to write it as u'&hellip;&lsquo;.
On the contrary, in Python 3.x, the default string is Unicode string.
If you want a byte string, you have to write it as b&rsquo;&hellip;&lsquo;.</p>

<p>In Python 3.3:</p>

<pre><code>chn = '将帖子翻译为中\n'
with open('py3uni', 'w') as f:
    f.write(chn)
print(chn.encode('utf-8'))
mygbk = chn.encode('gbk')
with open('py3gbk', 'wb') as f:
  f.write(mygbk)
readgbk = open('py3gbk', encoding='gbk').read()
print(readgbk)
print(type(readgbk))  # &lt;class 'str'&gt;
</code></pre>

<p>In Python 2.7:</p>

<pre><code># -*- encoding: utf-8 -*-
import codecs
inputStr = u'将帖子翻译为中文2015年3月\n'

gbkFn = 'gbkFile'
utf8Fn = 'utf8File'
print('Print original Unicdoe string: ' + inputStr)
print('Print in UTF-8 encoding: ' + inputStr.encode('utf-8'))
with codecs.open(utf8Fn, 'w', 'utf-8') as f:
    f.write(inputStr)
fromUTF8 = codecs.open(utf8Fn, encoding='utf-8').read()
with codecs.open(gbkFn, 'w', 'gbk') as f:
    f.write(inputStr)
fromGBK = codecs.open(gbkFn, encoding='gbk').read()
print('Strings from different encodings are the same?')
print(fromUTF8 == fromGBK)
print("\nString type:")
print(type(fromGBK))
</code></pre>

<p>You can convert gbkFile to utf8File in shell with:
<code>iconv -f gbk -t utf8 gbkFile &gt; utf8File</code>.</p>

<p>You can also write strings to file in this way:</p>

<pre><code>gbkStr = inputStr.encode('gbk')
with open('gbkFile', 'wb') as f:
    f.write(gbkStr)
</code></pre>

<p>While it&rsquo;s not as concise as the previous method.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Desktop Search Utility on Xfce]]></title>
    <link href="http://leetschau.github.io/blog/2013/07/02/091625/"/>
    <updated>2013-07-02T09:16:25+08:00</updated>
    <id>http://leetschau.github.io/blog/2013/07/02/091625</id>
    <content type="html"><![CDATA[<p>There is no Linux equivalent of Everything on Windows. All search tools have no incremental search funtion like that in Everthing.</p>

<p>The fastest filename search tool is &ldquo;find&rdquo; command and catfish. Pay attention that you have to do a &ldquo;Deep Search&rdquo; in catfish to perform a &ldquo;real&rdquo; search, or it only use &ldquo;locate&rdquo; command to search in the database.</p>

<p>This bug will be fixed in next release of catfish. By default catfish will not search files in hidden directories. So you have to use &ldquo;find&rdquo; command if you want getting all results including those in hidden directories.</p>

<p>Some Window Manager like Konqueror, Dolphin have filename search function, but they are too slow.</p>
]]></content>
  </entry>
  
</feed>
