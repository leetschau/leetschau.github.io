<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Mongo-connector | Dark Matter in Cyberspace]]></title>
  <link href="http://leetschau.github.io/blog/categories/mongo-connector/atom.xml" rel="self"/>
  <link href="http://leetschau.github.io/"/>
  <updated>2016-11-11T15:03:30+08:00</updated>
  <id>http://leetschau.github.io/</id>
  <author>
    <name><![CDATA[Li Chao]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Mongo-connector Dump Error and Solutions]]></title>
    <link href="http://leetschau.github.io/blog/2016/01/09/195735/"/>
    <updated>2016-01-09T19:57:35+08:00</updated>
    <id>http://leetschau.github.io/blog/2016/01/09/195735</id>
    <content type="html"><![CDATA[<p>When I synchronize data from a mongodb to a elasticsearch server with
<code>mongo-connector -m 192.168.100.3:27017 -t http://192.168.100.24:9200
 -d elastic_doc_manager --admin-username root --password xxx</code>,
the mongo-connector process quit with the following logs in
&ldquo;mongo-connector.log&rdquo; (all texts behind &ldquo;BulkIndexError&rdquo; are in the same line,
I rearrange the line for easy to understand):</p>

<pre><code>2016-01-09 19:05:52,457 [CRITICAL] mongo_connector.oplog_manager:543 - Exception during collection dump
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/mongo_connector/oplog_manager.py", line 495, in do_dump upsert_all(dm)
  ...
BulkIndexError: (u'10 document(s) failed to index.',
  [
    {
      u'index': {
        u'status': 400,
        u'_type': u'Fair',
        u'_id': u'4zWhZTJnqPCd2RK93',
        u'error': {
          u'caused_by': {
            u'reason': u'unknown property [latitude]',
            u'type': u'illegal_argument_exception'},
            u'reason': u'failed to parse [recurrence.location]',
            u'type': u'mapper_parsing_exception'},
            u'_index': u'staging'
      }
    },
    ...
  ]
</code></pre>

<p>When mongo-connector parse a document with <code>_id: 4zWhZTJnqPCd2RK93</code>
in Collection &ldquo;Fair&rdquo;, it &ldquo;failed to parse [recurrence.location]&rdquo;.
From <code>_index: staging</code>, we know collection Fair is in mongodb database &ldquo;staging&rdquo;.</p>

<p>List all &ldquo;recurrence.location&rdquo; of each document in staging database:</p>

<pre><code>$ mongo 192.168.100.3:27017/staging -u xxx -p xxx
foba:PRIMARY&gt; db.Fair.find({}, {"recurrence.location": 1})
{ "_id" : "h7Lo3hGLrFGEb6BK7", "recurrence" : [ { "location" : { "latitude" : 22.53, "longitude" : 114.06 } } ] }
{ "_id" : "Kd2e9w58P7vAScLDL", "recurrence" : [ { "location" : "" } ] }
{ "_id" : "4zWhZTJnqPCd2RK93", "recurrence" : [ { "location" : { "latitude" : 22.53, "longitude" : 114.06 } } ] }
</code></pre>

<p>It&rsquo;s now clear that the exception in synchronization is caused by
different structure of &ldquo;recurrence.location&rdquo;.</p>

<p>To guarantee mongo-connector synchronizing successfully,
you must keep all document in a collection share the same schema.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Synchronize Data From MongoDB to Elasticsearch]]></title>
    <link href="http://leetschau.github.io/blog/2015/10/31/011200/"/>
    <updated>2015-10-31T01:12:00+08:00</updated>
    <id>http://leetschau.github.io/blog/2015/10/31/011200</id>
    <content type="html"><![CDATA[<p>Your mongo replica set and elasticsearch are hosted on 2 servers.
The mongo server is on &ldquo;mip:mport&rdquo;.
The ES server is on &ldquo;esip:esport&rdquo;.</p>

<p>On another server, install <a href="https://github.com/mongodb-labs/mongo-connector">mongo-connector</a>
with <code>pip install mongo-connector</code>.
If there are some errors, it may be caused by absence of gcc.
On Ubuntu, install them with <code>sudo apt-get install build-essential python-dev</code>.</p>

<pre><code>mongo-connector -m mip:mport -t esip:esport -d elastic_doc_manager --admin-username root --password rootPwd
</code></pre>

<p>That&rsquo;s it!
Now when you insert documents into MongoDB,
you can see it on elasticsearch.</p>

<p>We&rsquo;ve studied Mongo River and Mongoosatic, neither is better than this.</p>

<p>Note 1 (2015.11.15):</p>

<p>阿里云服务器上，用普通用户es启动es服务(<code>bin/elasticsearch</code>)，同一用户启动mongo-connector后，报
&ldquo;AttributeError: &lsquo;IndicesClient&rsquo; object has no attribute &lsquo;delete_mapping&rsquo;"错误，
es版本为2.0，mongo-connector版本为2.1，将es版本改为1.7，mongo-connector改为1.3后，
仍然出现这一错误，原因是MongoDB中删除了test库中的一个Collection，但ES中仍然有，就会出现这个错误，
解决方法是清空ES的test重新同步一遍：
<code>curl -XDELETE http://123.57.188.18:9322/test</code>.
Ref: <a href="https://github.com/mongodb-labs/mongo-connector/issues/349">https://github.com/mongodb-labs/mongo-connector/issues/349</a></p>

<p>Note 2:</p>

<p>Use root to sync is unsafe.
We create an user with &ldquo;clusterManager&rdquo; role to do this work.
Login with root, and run:</p>

<pre><code>use admin
db.createUser(
    {
      user: "clustermgr",
      pwd: "cmpwd",
      roles: [ "clusterManager" ]
    }
)
</code></pre>

<p>But run the command
<code>mongo-connector -m 119.254.211.28:15515 -t localhost:9200 -d elastic_doc_manager --admin-username clustermgr --password cmpwd</code>
will be the error <code>OperationFailure: database error: not authorized for query on local.oplog.rs</code>.</p>
]]></content>
  </entry>
  
</feed>
