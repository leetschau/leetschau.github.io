<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Streaming | Dark Matter in Cyberspace]]></title>
  <link href="http://leetschau.github.io/blog/categories/streaming/atom.xml" rel="self"/>
  <link href="http://leetschau.github.io/"/>
  <updated>2015-11-20T11:01:10+08:00</updated>
  <id>http://leetschau.github.io/</id>
  <author>
    <name><![CDATA[Li Chao]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Run Python MapReduce on Hadoop Cluster]]></title>
    <link href="http://leetschau.github.io/blog/2014/08/07/112649/"/>
    <updated>2014-08-07T11:26:49+08:00</updated>
    <id>http://leetschau.github.io/blog/2014/08/07/112649</id>
    <content type="html"><![CDATA[<p>Based on <a href="http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/">Writing an Hadoop MapReduce Program in Python</a>.</p>

<ol>
<li>Create mapper and reducer script and make them executable with <code>chmod 755 *.py</code>:</li>
</ol>


<p>mapper.py:</p>

<pre><code>#!/usr/bin/env python
import sys
# input comes from STDIN (standard input)
for line in sys.stdin:
    # remove leading and trailing whitespace
    line = line.strip()
    # split the line into words
    words = line.split()
    # increase counters
    for word in words:
        # write the results to STDOUT (standard output); what we output here will be the input for the Reduce step, i.e. the input for reducer.py tab-delimited; the trivial word count is 1
        print '%s\t%s' % (word, 1)
</code></pre>

<p>reducer.py:</p>

<pre><code>#!/usr/bin/env python

from operator import itemgetter
import sys

current_word = None
current_count = 0
word = None

# input comes from STDIN
for line in sys.stdin:
    # remove leading and trailing whitespace
    line = line.strip()

    # parse the input we got from mapper.py
    word, count = line.split('\t', 1)

    # convert count (currently a string) to int
    try:
        count = int(count)
    except ValueError:
        # count was not a number, so silently ignore/discard this line
        continue

    # this IF-switch only works because Hadoop sorts map output by key (here: word) before it is passed to the reducer
    if current_word == word:
        current_count += count
    else:
        if current_word:
            # write result to STDOUT
            print '%s\t%s' % (current_word, current_count)
        current_count = count
        current_word = word

# do not forget to output the last word if needed!
if current_word == word:
    print '%s\t%s' % (current_word, current_count)
</code></pre>

<ol>
<li><p>Get input text file and put them into hdfs: download the text version of <a href="http://www.gutenberg.org/etext/20417">The Outline of Science, Vol. 1 (of 4) by J. Arthur Thomson</a>, <a href="http://www.gutenberg.org/etext/5000">The Notebooks of Leonardo Da Vinci</a> and <a href="http://www.gutenberg.org/etext/4300">Ulysses by James Joyce</a>. Then upload them to hdfs:</p>

<p> $ hadoop fs -mkdir gutenberg
 $ hadoop fs -put pg<em>.txt gutenberg/
 $ hadoop jar /usr/lib/hadoop-0.20-mapreduce/contrib/streaming/hadoop-</em>streaming<em>.jar -file /home/hduser/mapper.py -mapper /home/hduser/mapper.py -file /home/hduser/reducer.py -reducer /home/hduser/reducer.py -input /user/hduser/gutenberg/</em> -output /user/hduser/gutenberg-output</p></li>
</ol>


<p>You have to make sure the &ldquo;gutenberg-output&rdquo; folder has not existed. When finished, you can see the result with:</p>

<pre><code>$ hadoop fs -ls gutenberg-output
$ hadoop fs -cat gutenberg-output/part-00000
</code></pre>

<p>Verified on CDH 4.3, built on 8 CentOS 6.3 64bit host, Python 2.6.6, 2014-8-7.</p>
]]></content>
  </entry>
  
</feed>
