<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Duplicate | Dark Matter in Cyberspace]]></title>
  <link href="http://leetschau.github.io/blog/categories/duplicate/atom.xml" rel="self"/>
  <link href="http://leetschau.github.io/"/>
  <updated>2015-06-01T12:52:39+08:00</updated>
  <id>http://leetschau.github.io/</id>
  <author>
    <name><![CDATA[Li Chao]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[查找重复文件并删除的工具]]></title>
    <link href="http://leetschau.github.io/blog/2013/01/05/170751/"/>
    <updated>2013-01-05T17:07:51+08:00</updated>
    <id>http://leetschau.github.io/blog/2013/01/05/170751</id>
    <content type="html"><![CDATA[<p><a href="http://www.alldup.de/alldup_help/alldup.htm">AllDup</a>的Portable版：AllDupPortable.zip，今天用它查找重复的电子书，效果良好。</p>

<p>基本使用方法是：在"Source Folder"里选择要查找重复文件的文件夹，例如e:\mydoc\books，然后在"Search Criteria"里设置好判定为相同文件的条件，一般选择文件名和大小相同，然后点"Start Search"按钮就开始查找了。</p>

<p>此类软件介绍见<a href="http://www.freewaregenius.com/easily-find-and-remove-duplicate-files-with-alldup-for-windows/%E3%80%82">http://www.freewaregenius.com/easily-find-and-remove-duplicate-files-with-alldup-for-windows/%E3%80%82</a></p>
]]></content>
  </entry>
  
</feed>
