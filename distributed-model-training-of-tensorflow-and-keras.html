<!DOCTYPE html>
<html lang="en-US">
    <head>
        <meta charset="utf-8"> 
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Li Chao" />
        <meta name="copyright" content="Li Chao" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="tensorflow, keras, distributed, Tech, " />

<meta property="og:title" content="Distributed Model Training of TensorFlow and Keras"/>
<meta property="og:url" content="http://leetschau.github.io/distributed-model-training-of-tensorflow-and-keras.html" />
<meta property="og:description" content="Environment setup: see dsnote &#34;Setup Tensorflow GPU on CentOS 7&#34;. Multiple GPUs on single host The corresponding strategy for this scenario is tf.distribute.MirroredStrategy. The demo codes: import tensorflow as tf mirrored_strategy = tf.distribute.MirroredStrategy() with mirrored_strategy.scope(): model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1 …" />
<meta property="og:site_name" content="DarkMatter in Cyberspace" />
<meta property="og:article:author" content="Li Chao" />
<meta property="og:article:published_time" content="2020-06-02T13:53:01+08:00" />
<meta property="" content="2020-07-16T14:59:35+08:00" />
<meta name="twitter:title" content="Distributed Model Training of TensorFlow and Keras">
<meta name="twitter:description" content="Environment setup: see dsnote &#34;Setup Tensorflow GPU on CentOS 7&#34;. Multiple GPUs on single host The corresponding strategy for this scenario is tf.distribute.MirroredStrategy. The demo codes: import tensorflow as tf mirrored_strategy = tf.distribute.MirroredStrategy() with mirrored_strategy.scope(): model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1 …">

        <title>Distributed Model Training of TensorFlow and Keras · DarkMatter in Cyberspace
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.1/css/font-awesome.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="http://leetschau.github.io/theme/css/pygments.css" media="screen">
        <link rel="stylesheet" type="text/css" href="http://leetschau.github.io/theme/tipuesearch/tipuesearch.css" media="screen">
        <link rel="stylesheet" type="text/css" href="http://leetschau.github.io/theme/css/elegant.css" media="screen">
        <link rel="stylesheet" type="text/css" href="http://leetschau.github.io/theme/css/custom.css" media="screen">
    </head>
    <body>
        <div id="content-sans-footer">
        <div class="navbar navbar-static-top">
            <div class="navbar-inner">
                <div class="container-fluid">
                    <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </a>
                    <a class="brand" href="http://leetschau.github.io/"><span class=site-name>DarkMatter in Cyberspace</span></a>
                    <div class="nav-collapse collapse">
                        <ul class="nav pull-right top-menu">
                            <li ><a href="http://leetschau.github.io">Home</a></li>
                            <li ><a href="http://leetschau.github.io/categories.html">Categories</a></li>
                            <li ><a href="http://leetschau.github.io/tags.html">Tags</a></li>
                            <li ><a href="http://leetschau.github.io/archives.html">Archives</a></li>
                            <li><form class="navbar-search" action="http://leetschau.github.io/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div class="container-fluid">
            <div class="row-fluid">
                <div class="span1"></div>
                <div class="span10">
<article>
<div class="row-fluid">
    <header class="page-header span10 offset2">
    <h1><a href="http://leetschau.github.io/distributed-model-training-of-tensorflow-and-keras.html"> Distributed Model Training of TensorFlow and Keras </a></h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">

            
            <hr>
<p>Environment setup: see dsnote "Setup Tensorflow GPU on CentOS 7".</p>
<h1>Multiple GPUs on single host</h1>
<p>The corresponding <em>strategy</em> for this scenario is
<code>tf.distribute.MirroredStrategy</code>.</p>
<p>The demo codes:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">mirrored_strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">MirroredStrategy</span><span class="p">()</span>
<span class="k">with</span> <span class="n">mirrored_strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span> 
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,))])</span> 
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;sgd&#39;</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensors</span><span class="p">(([</span><span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">]))</span><span class="o">.</span><span class="kp">repeat</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">ones</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="kp">ones</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div>


<p>Another demo (verified on 50 server, 2020.6.4):</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>

<span class="n">mnist</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mf">255.0</span>

<span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">MirroredStrategy</span><span class="p">()</span>

<span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>
    <span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div>


<h1>Multiple GPUs on multiple hosts</h1>
<h2>MultiWorkerMirroredStrategy</h2>
<h3>Single node demo</h3>
<p>The following codes are for verification on each worker of the cluster:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># fix issue #24496</span>
<span class="kn">from</span> <span class="nn">tensorflow.compat.v1</span> <span class="kn">import</span> <span class="n">ConfigProto</span>
<span class="kn">from</span> <span class="nn">tensorflow.compat.v1</span> <span class="kn">import</span> <span class="n">InteractiveSession</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">ConfigProto</span><span class="p">()</span>
<span class="n">config</span><span class="o">.</span><span class="n">gpu_options</span><span class="o">.</span><span class="n">allow_growth</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">session</span> <span class="o">=</span> <span class="n">InteractiveSession</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="k">def</span> <span class="nf">mnist_dataset</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
    <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mi">255</span><span class="p">)</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="kp">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span>
        <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span><span class="o">.</span><span class="kp">shuffle</span><span class="p">(</span><span class="mi">60000</span><span class="p">)</span><span class="o">.</span><span class="kp">repeat</span><span class="p">()</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">train_dataset</span>

<span class="k">def</span> <span class="nf">build_and_compile_cnn_model</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="kp">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">target_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="p">])</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="n">per_worker_batch_size</span> <span class="o">=</span> <span class="mi">64</span>

<span class="n">single_worker_dataset</span> <span class="o">=</span> <span class="n">mnist_dataset</span><span class="p">(</span><span class="n">per_worker_batch_size</span><span class="p">)</span>
<span class="n">single_worker_model</span> <span class="o">=</span> <span class="n">build_and_compile_cnn_model</span><span class="p">()</span>
<span class="n">single_worker_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">single_worker_dataset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="o">=</span><span class="mi">70</span><span class="p">)</span>
</code></pre></div>


<h3>Multi-workers on the same host</h3>
<p>不论多个 worker 是不是在一台主机上，每个 worker 对应一个模型训练脚本，
这些脚本除了 TF_CONFIG.task.index 不同，其他完全一样。</p>
<p>依次执行这些脚本，先启动的会等待后启动的，直到最后一个 worker 启动后开始训练。</p>
<p>下面的脚本复制一份并将 TF_CONFIG.task.index 改为 1 后，
在 50 (TF 2.1.0) 和 220 (TF 1.14.0) 上运行成功：</p>
<div class="highlight"><pre><span></span><code><span class="c1"># fix issue #24496 of TF 2.x</span>
<span class="c1"># unnecessary for tf 1.x</span>
<span class="kn">from</span> <span class="nn">tensorflow.compat.v1</span> <span class="kn">import</span> <span class="n">ConfigProto</span>
<span class="kn">from</span> <span class="nn">tensorflow.compat.v1</span> <span class="kn">import</span> <span class="n">InteractiveSession</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">ConfigProto</span><span class="p">()</span>
<span class="n">config</span><span class="o">.</span><span class="n">gpu_options</span><span class="o">.</span><span class="n">allow_growth</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">session</span> <span class="o">=</span> <span class="n">InteractiveSession</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="c1"># put this before model definitions to avoid issue #34568</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;TF_CONFIG&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="kp">dumps</span><span class="p">({</span>
    <span class="s1">&#39;cluster&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;worker&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;localhost:12345&quot;</span><span class="p">,</span> <span class="s2">&quot;localhost:23456&quot;</span><span class="p">]</span>
    <span class="p">},</span>
    <span class="s1">&#39;task&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;worker&#39;</span><span class="p">,</span> <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
<span class="p">})</span>

<span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">MultiWorkerMirroredStrategy</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">mnist_dataset</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
    <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mi">255</span><span class="p">)</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="kp">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span>
        <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span><span class="o">.</span><span class="kp">shuffle</span><span class="p">(</span><span class="mi">60000</span><span class="p">)</span><span class="o">.</span><span class="kp">repeat</span><span class="p">()</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">train_dataset</span>

<span class="k">def</span> <span class="nf">build_and_compile_cnn_model</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="kp">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">target_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="p">])</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="n">num_workers</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">per_worker_batch_size</span> <span class="o">=</span> <span class="mi">64</span>

<span class="n">global_batch_size</span> <span class="o">=</span> <span class="n">per_worker_batch_size</span> <span class="o">*</span> <span class="n">num_workers</span>
<span class="n">multi_worker_dataset</span> <span class="o">=</span> <span class="n">mnist_dataset</span><span class="p">(</span><span class="n">global_batch_size</span><span class="p">)</span>

<span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>
    <span class="n">multi_worker_model</span> <span class="o">=</span> <span class="n">build_and_compile_cnn_model</span><span class="p">()</span>

<span class="n">multi_worker_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">multi_worker_dataset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="o">=</span><span class="mi">70</span><span class="p">)</span>

<span class="c1"># according to issue #35100, the followoing warning is superfluous:</span>
<span class="c1"># Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled</span>
</code></pre></div>


<h3>Multi-workers on different hosts</h3>
<p>注意不同主机必须在同一个子网里，下面是 220 和 221 服务器 avatar 的
~/dist_tf/extip.py 文件：</p>
<div class="highlight"><pre><span></span><code><span class="err">os.environ[&#39;TF_CONFIG&#39;] = json.dumps({</span>
<span class="err">    &#39;cluster&#39;: {</span>
<span class="err">        &#39;worker&#39;: [&quot;172.15.106.220:12345&quot;, &quot;172.15.106.221:23456&quot;]</span>
<span class="err">    },</span>
<span class="err">    &#39;task&#39;: {&#39;type&#39;: &#39;worker&#39;, &#39;index&#39;: 0}</span>
<span class="err">})</span>
</code></pre></div>


<p>221 上只修改 task.index:</p>
<div class="highlight"><pre><span></span><code><span class="err">...</span>
<span class="err">    &#39;task&#39;: {&#39;type&#39;: &#39;worker&#39;, &#39;index&#39;: 1}</span>
<span class="err">...</span>
</code></pre></div>


<p>在 220 和 221 上分别运行：
<code>/opt/app/anaconda3/bin/python extip.py</code>.</p>
<p>Fix TF bug <code>Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR</code>:
see tf <a href="https://github.com/tensorflow/tensorflow/issues/24496">issue #24496</a>.</p>
<h4>Multi-workers on different hosts for TF 2.x</h4>
<p>运行脚本与上节相同，但 49 上的配置为：</p>
<div class="highlight"><pre><span></span><code><span class="err">os.environ[&#39;TF_CONFIG&#39;] = json.dumps({</span>
<span class="err">    &#39;cluster&#39;: {</span>
<span class="err">        &#39;worker&#39;: [&quot;192.168.2.49:12345&quot;, &quot;192.168.2.50:23456&quot;]</span>
<span class="err">    },</span>
<span class="err">    &#39;task&#39;: {&#39;type&#39;: &#39;worker&#39;, &#39;index&#39;: 0}</span>
<span class="err">})</span>
</code></pre></div>


<p>50 的配置为：</p>
<div class="highlight"><pre><span></span><code><span class="err">os.environ[&#39;TF_CONFIG&#39;] = json.dumps({</span>
<span class="err">    &#39;cluster&#39;: {</span>
<span class="err">        &#39;worker&#39;: [&quot;192.168.2.49:12345&quot;, &quot;192.168.2.50:23456&quot;]</span>
<span class="err">    },</span>
<span class="err">    &#39;task&#39;: {&#39;type&#39;: &#39;worker&#39;, &#39;index&#39;: 1}</span>
<span class="err">})</span>
</code></pre></div>


<p>分别在两台主机上启动脚本，由于 tensorfow Keras API 的 bug <a href="https://github.com/tensorflow/tensorflow/issues/33531">issue 33531</a>，
在计算第一个 epoch 时卡死，日志中有下面的错误：</p>
<div class="highlight"><pre><span></span><code><span class="err">Error Found an unshardable source dataset: name &quot;TensorSliceDataset/_2&quot;</span>
</code></pre></div>


<p>社区目前还没有 fix 这个 bug，
基于 Keras API 的多主机多节点的分布式训练目前不可用。</p>
<p>Deprecated:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="n">multiworker_strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">MultiWorkerMirroredStrategy</span><span class="p">()</span>

<span class="c1"># or specify the implementation of collective ops: NCCL (the other one is gRPC)</span>
<span class="n">multiworker_strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">MultiWorkerMirroredStrategy</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">CollectiveCommunication</span><span class="o">.</span><span class="n">NCCL</span><span class="p">)</span>
</code></pre></div>


<h2>ParameterServerStrategy</h2>
<p>In this setup, some nodes(machines) are designated as workers
and some as parameter servers. Each variable of the model is placed on one parameter server.
Computation is replicated across all GPUs of all workers.</p>
<p>This is suitable for the scenario where you have some machines without GPUs,
but on the other machines GPUs is installed.</p>
<p>根据 <a href="https://www.tensorflow.org/guide/distributed_training#types_of_strategies">Distributed training with TensorFlow</a>，
TF.Keras 在 2.3 之后支持 ParameterServerStrategy，
目前的 Keras 分布式教程 <a href="https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras">Multi-worker training with Keras</a>
只使用 MultiWorkerMirroredStrategy，
所以等后续 Keras 支持 ParameterServerStrategy 后再验证。</p>
<p>Ref:</p>
<ul>
<li>
<p>Chapter 19 of Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd edition.</p>
</li>
<li>
<p><a href="https://www.tensorflow.org/guide/distributed_training">Distributed training with TensorFlow</a></p>
</li>
<li>
<p><a href="https://www.tensorflow.org/tutorials/distribute/keras">Distributed training with Keras</a></p>
</li>
</ul>
            
            
            <hr/>
            <script src="https://utteranc.es/client.js"
                    repo="leetschau/leetschau.github.io"
                    issue-term="pathname"
                    theme="github-light"
                    crossorigin="anonymous"
                    async>
            </script>
            <hr/>
        </div>
        <section>
        <div class="span2" style="float:right;font-size:0.9em;">
            <h4>Published</h4>
            <time pubdate="pubdate" datetime="2020-06-02T13:53:01+08:00">Jun 2, 2020</time>

<h4>Last Updated</h4>
<time datetime="2020-07-16T14:59:35+08:00">Jul 16, 2020</time>

            <h4>Category</h4>
            <a class="category-link" href="http://leetschau.github.io/categories.html#tech-ref">Tech</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="http://leetschau.github.io/tags.html#distributed-ref">distributed
                    <span>2</span>
</a></li>
                <li><a href="http://leetschau.github.io/tags.html#keras-ref">keras
                    <span>3</span>
</a></li>
                <li><a href="http://leetschau.github.io/tags.html#tensorflow-ref">tensorflow
                    <span>3</span>
</a></li>
            </ul>
<h4>Contact</h4>
    <a href="#" title="My You can add links in your config file Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-you can add links in your config file sidebar-social-links"></i></a>
    <a href="#" title="My Another social link Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-another social link sidebar-social-links"></i></a>
        </div>
        </section>
</div>
</article>
                </div>
                <div class="span1"></div>
            </div>
        </div>
        <div id="push"></div>
    </div>
<footer>
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page">Pelican</a>. Theme: <a href="http://oncrashreboot.com/pelican-elegant" title="Theme Elegant Home Page">Elegant</a> by <a href="http://oncrashreboot.com" title="Talha Mansoor Home Page">Talha Mansoor</a></li>
    </ul>
</div>
</footer>            <script src="http://code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    
    </body>
    <!-- Theme: Elegant built for Pelican
    License : http://oncrashreboot.com/pelican-elegant -->
</html>